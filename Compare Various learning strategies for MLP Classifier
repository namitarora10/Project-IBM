import numpy as np
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_digits, load_iris, load_wine
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score

# Load datasets
datasets = {
    'Digits': load_digits(),
    'Iris': load_iris(),
    'Wine': load_wine()
}

# MLP configurations to compare
mlp_configs = [
    {'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver': 'adam'},
    {'hidden_layer_sizes': (50, 50), 'activation': 'tanh', 'solver': 'sgd'},
    {'hidden_layer_sizes': (50, 50), 'activation': 'logistic', 'solver': 'adam'}
]

for dataset_name, dataset in datasets.items():
    X = dataset.data
    y = dataset.target

    # Standardize the features
    scaler = StandardScaler()
    X = scaler.fit_transform(X)

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    print(f"\nDataset: {dataset_name}")

    for config in mlp_configs:
        mlp = MLPClassifier(**config, random_state=42)

        # Cross-validation
        cv_scores = cross_val_score(mlp, X_train, y_train, cv=5)

        print(f"\nConfiguration: {config}")
        print(f"Cross-validation Accuracy: {np.mean(cv_scores):.4f} +/- {np.std(cv_scores):.4f}")

        # Train the model on the full training set
        mlp.fit(X_train, y_train)

        # Evaluate on the test set
        y_pred = mlp.predict(X_test)
        test_accuracy = accuracy_score(y_test, y_pred)

        print(f"Test Accuracy: {test_accuracy:.4f}")
